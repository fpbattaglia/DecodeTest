{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Multivariate Decoding Analysis for Neural Replay\n",
    "\n",
    "Based on **Liu et al. (2019) Cell**: *Human Replay Spontaneously Reorganizes Experience*\n",
    "\n",
    "This notebook demonstrates the multivariate decoding algorithm for detecting sequential replay of neural representations during rest periods.\n",
    "\n",
    "## Key Concepts\n",
    "\n",
    "1. **Stimulus Decoders**: Train classifiers to recognize neural patterns associated with each stimulus\n",
    "2. **Reactivation Detection**: Apply decoders to rest periods to detect spontaneous reactivations\n",
    "3. **Sequenceness Measure**: Quantify the degree to which reactivations follow a sequential structure\n",
    "4. **Statistical Testing**: Use permutation tests to establish significance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "import numpy as np\nimport matplotlib.pyplot as plt\nfrom sklearn.model_selection import cross_val_score\nimport seaborn as sns\n\n# Import the replay_decoder package\nfrom replay_decoder import (\n    MultivariateReplayDecoder,\n    create_linear_transition_matrix,\n    plot_sequenceness\n)\n\n# Set style\nplt.style.use('seaborn-v0_8-darkgrid')\nsns.set_palette(\"husl\")\n\nprint(\"Libraries imported successfully!\")"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## Part 1: Example 1 - Basic Simulation with Forward Replay\n",
    "\n",
    "We'll simulate a simple scenario:\n",
    "- 4 states: A, B, C, D\n",
    "- Sequence: A → B → C → D\n",
    "- Replay lag: 40ms (as in the paper)\n",
    "\n",
    "The `MultivariateReplayDecoder` class is imported from the `replay_decoder` package."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set random seed for reproducibility\n",
    "np.random.seed(42)\n",
    "\n",
    "# Parameters\n",
    "n_trials = 200\n",
    "n_timepoints_per_trial = 50  # 500ms at 100Hz\n",
    "n_sensors = 100\n",
    "n_states = 4\n",
    "\n",
    "print(\"Creating simulated training data...\")\n",
    "print(f\"  - {n_trials} trials\")\n",
    "print(f\"  - {n_states} states (A, B, C, D)\")\n",
    "print(f\"  - {n_sensors} sensors\")\n",
    "print(f\"  - {n_timepoints_per_trial} timepoints per trial (500ms)\")\n",
    "\n",
    "# Simulate training data (functional localizer)\n",
    "X_train = np.random.randn(n_trials, n_timepoints_per_trial, n_sensors) * 0.5\n",
    "y_train = np.random.randint(0, n_states, n_trials)\n",
    "\n",
    "# Add signal at 200ms for each state\n",
    "time_idx = 20  # 200ms\n",
    "for trial in range(n_trials):\n",
    "    state = y_train[trial]\n",
    "    # Add state-specific pattern to specific sensors\n",
    "    X_train[trial, time_idx, state*10:(state+1)*10] += 2.0\n",
    "\n",
    "print(\"\\nTraining data created!\")\n",
    "print(f\"Shape: {X_train.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize training data\n",
    "fig, axes = plt.subplots(2, 2, figsize=(12, 8))\n",
    "axes = axes.ravel()\n",
    "\n",
    "state_names = ['A', 'B', 'C', 'D']\n",
    "for state in range(n_states):\n",
    "    # Get trials for this state\n",
    "    state_trials = X_train[y_train == state]\n",
    "\n",
    "    # Average across trials and plot\n",
    "    avg_activity = state_trials.mean(axis=0)  # (timepoints, sensors)\n",
    "\n",
    "    im = axes[state].imshow(avg_activity.T, aspect='auto', cmap='RdBu_r',\n",
    "                            vmin=-0.5, vmax=0.5, origin='lower')\n",
    "    axes[state].set_xlabel('Time (ms)', fontsize=10)\n",
    "    axes[state].set_ylabel('Sensor', fontsize=10)\n",
    "    axes[state].set_title(f'State {state_names[state]} - Average Activity', fontsize=12, fontweight='bold')\n",
    "    axes[state].axvline(x=20, color='yellow', linestyle='--', linewidth=2, label='Decoding timepoint')\n",
    "    axes[state].legend(loc='upper right', fontsize=8)\n",
    "\n",
    "    # Set x-axis labels in milliseconds\n",
    "    xticks = axes[state].get_xticks()\n",
    "    axes[state].set_xticklabels([int(x*10) for x in xticks])\n",
    "\n",
    "plt.colorbar(im, ax=axes, label='Activity (a.u.)', fraction=0.046, pad=0.04)\n",
    "plt.tight_layout()\n",
    "plt.savefig('training_data_heatmap.png', dpi=150, bbox_inches='tight')\n",
    "plt.show()\n",
    "\n",
    "print(\"Training data visualization saved!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize and train decoder\n",
    "print(\"Initializing decoder...\")\n",
    "decoder = MultivariateReplayDecoder(n_states=n_states, max_lag_ms=600, sampling_rate=100)\n",
    "\n",
    "print(\"\\nTraining classifiers...\")\n",
    "decoder.train_classifiers(X_train, y_train, time_point_ms=200, C=1.0)\n",
    "\n",
    "# Evaluate decoder performance with cross-validation\n",
    "print(\"\\nEvaluating decoder performance (cross-validation)...\")\n",
    "time_idx = 20\n",
    "X_at_time = X_train[:, time_idx, :]\n",
    "\n",
    "for state in range(n_states):\n",
    "    y_binary = (y_train == state).astype(int)\n",
    "    scores = cross_val_score(decoder.classifiers[state],\n",
    "                            decoder.scalers[state].transform(X_at_time),\n",
    "                            y_binary, cv=5, scoring='roc_auc')\n",
    "    print(f\"  State {state_names[state]}: AUC = {scores.mean():.3f} ± {scores.std():.3f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Simulate resting state data with embedded replay\n",
    "print(\"Simulating resting state with replay sequence A→B→C→D...\")\n",
    "n_rest_timepoints = 3000  # 30 seconds at 100Hz\n",
    "X_rest = np.random.randn(n_rest_timepoints, n_sensors) * 0.3\n",
    "\n",
    "# Embed sequence A→B→C→D at 40ms lag, at multiple time points\n",
    "lag_samples = 4  # 40ms at 100Hz\n",
    "sequence = [0, 1, 2, 3]  # A→B→C→D\n",
    "replay_times = []\n",
    "\n",
    "for start_time in range(100, n_rest_timepoints - 100, 200):\n",
    "    replay_times.append(start_time)\n",
    "    for step, state in enumerate(sequence):\n",
    "        time_point = start_time + step * lag_samples\n",
    "        if time_point < n_rest_timepoints:\n",
    "            # Add signal to state-specific sensors\n",
    "            X_rest[time_point, state*10:(state+1)*10] += 1.5\n",
    "\n",
    "print(f\"  Embedded {len(replay_times)} replay events\")\n",
    "print(f\"  Replay lag: 40ms between states\")\n",
    "print(f\"  Replay interval: ~200ms between events\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Decode states from resting data\n",
    "print(\"\\nDecoding states from resting data...\")\n",
    "reactivation_probs = decoder.decode_states(X_rest)\n",
    "print(f\"  Reactivation matrix shape: {reactivation_probs.shape}\")\n",
    "print(f\"  Time resolution: 10ms\")\n",
    "\n",
    "# Visualize reactivations\n",
    "fig, ax = plt.subplots(figsize=(14, 5))\n",
    "\n",
    "# Plot first 5 seconds\n",
    "time_window = slice(0, 500)\n",
    "time_ms = np.arange(500) * 10\n",
    "\n",
    "for state in range(n_states):\n",
    "    ax.plot(time_ms, reactivation_probs[time_window, state],\n",
    "           label=f'State {state_names[state]}', linewidth=1.5, alpha=0.8)\n",
    "\n",
    "# Mark embedded replay events\n",
    "for rt in replay_times:\n",
    "    if rt < 500:\n",
    "        ax.axvline(x=rt*10, color='red', linestyle='--', alpha=0.3, linewidth=1)\n",
    "\n",
    "ax.set_xlabel('Time (ms)', fontsize=12)\n",
    "ax.set_ylabel('Reactivation Probability', fontsize=12)\n",
    "ax.set_title('State Reactivations During Rest (First 5 seconds)', fontsize=14, fontweight='bold')\n",
    "ax.legend(loc='upper right', ncol=4)\n",
    "ax.grid(True, alpha=0.3)\n",
    "plt.tight_layout()\n",
    "plt.savefig('reactivation_timeseries.png', dpi=150, bbox_inches='tight')\n",
    "plt.show()\n",
    "\n",
    "print(\"Reactivation visualization saved!\")"
   ]
  },
  {
   "cell_type": "code",
   "source": "# Define transition matrix for A→B→C→D using the helper function\ntransition_matrix = create_linear_transition_matrix(n_states)\n\nprint(\"Transition matrix (A→B→C→D):\")\nprint(transition_matrix)\n\n# Visualize transition matrix\nfig, ax = plt.subplots(figsize=(6, 5))\nim = ax.imshow(transition_matrix, cmap='Blues', vmin=0, vmax=1)\nax.set_xticks(range(n_states))\nax.set_yticks(range(n_states))\nax.set_xticklabels(state_names)\nax.set_yticklabels(state_names)\nax.set_xlabel('To State', fontsize=12)\nax.set_ylabel('From State', fontsize=12)\nax.set_title('Hypothesized Transition Matrix', fontsize=14, fontweight='bold')\n\n# Add text annotations\nfor i in range(n_states):\n    for j in range(n_states):\n        text = ax.text(j, i, int(transition_matrix[i, j]),\n                      ha=\"center\", va=\"center\", color=\"black\", fontsize=16)\n\nplt.colorbar(im, ax=ax, label='Transition')\nplt.tight_layout()\nplt.savefig('transition_matrix.png', dpi=150, bbox_inches='tight')\nplt.show()",
   "metadata": {},
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# Compute sequenceness\nprint(\"Computing sequenceness...\")\nsequenceness, time_lags = decoder.compute_sequenceness(\n    reactivation_probs, transition_matrix, alpha_control=True\n)\n\n# Find peak\npeak_idx = np.argmax(np.abs(sequenceness))\npeak_lag = time_lags[peak_idx]\npeak_value = sequenceness[peak_idx]\n\nprint(f\"\\nResults:\")\nprint(f\"  Peak sequenceness: {peak_value:.4f}\")\nprint(f\"  Peak lag: {peak_lag}ms\")\nprint(f\"  Expected lag: 40ms (embedded in data)\")\nprint(f\"  Direction: {'Forward' if peak_value > 0 else 'Backward'}\")"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# Run permutation test\nprint(\"\\nRunning permutation test (500 permutations)...\")\nprint(\"This may take a minute...\")\n\np_values, threshold, true_seq = decoder.permutation_test(\n    reactivation_probs, transition_matrix, n_permutations=500\n)\n\nsignificant_lags = time_lags[p_values < 0.05]\nprint(f\"\\nStatistical Results:\")\nprint(f\"  Significance threshold: {threshold:.4f}\")\nprint(f\"  Number of significant lags: {len(significant_lags)}\")\nif len(significant_lags) > 0:\n    print(f\"  Significant time lags: {significant_lags}ms\")\n    print(f\"  Peak p-value: {p_values[peak_idx]:.4f}\")"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize sequenceness results\n",
    "fig, (ax1, ax2) = plt.subplots(2, 1, figsize=(12, 8))\n",
    "\n",
    "# Plot 1: Sequenceness\n",
    "ax1.plot(time_lags, sequenceness, 'b-', linewidth=2.5, label='Sequenceness')\n",
    "ax1.axhline(y=0, color='k', linestyle='--', alpha=0.3)\n",
    "ax1.axhline(y=threshold, color='r', linestyle='--', linewidth=2, label=f'Threshold (p<0.05)')\n",
    "ax1.axhline(y=-threshold, color='r', linestyle='--', linewidth=2)\n",
    "ax1.axvline(x=40, color='green', linestyle=':', linewidth=2, alpha=0.7, label='True lag (40ms)')\n",
    "ax1.fill_between(time_lags, 0, sequenceness, where=(sequenceness > threshold),\n",
    "                 alpha=0.3, color='blue', label='Significant')\n",
    "ax1.set_xlabel('Time Lag (ms)', fontsize=12)\n",
    "ax1.set_ylabel('Sequenceness\\n(Forward - Backward)', fontsize=12)\n",
    "ax1.set_title('Example 1: Forward Replay Detection (A→B→C→D)', fontsize=14, fontweight='bold')\n",
    "ax1.legend(loc='upper right')\n",
    "ax1.grid(True, alpha=0.3)\n",
    "\n",
    "# Plot 2: P-values\n",
    "ax2.plot(time_lags, p_values, 'purple', linewidth=2)\n",
    "ax2.axhline(y=0.05, color='r', linestyle='--', linewidth=2, label='p=0.05')\n",
    "ax2.fill_between(time_lags, 0, p_values, where=(p_values < 0.05),\n",
    "                alpha=0.3, color='purple')\n",
    "ax2.set_xlabel('Time Lag (ms)', fontsize=12)\n",
    "ax2.set_ylabel('P-value', fontsize=12)\n",
    "ax2.set_title('Statistical Significance', fontsize=12)\n",
    "ax2.set_yscale('log')\n",
    "ax2.legend()\n",
    "ax2.grid(True, alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig('sequenceness_example1.png', dpi=150, bbox_inches='tight')\n",
    "plt.show()\n",
    "\n",
    "print(\"\\nSequenceness analysis complete!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "## Part 2: Example 2 - Reverse Replay After Reward\n\nThe paper showed that replay reverses direction after reward. Let's simulate this phenomenon."
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# Simulate resting state with REVERSE replay (D→C→B→A)\nprint(\"Simulating resting state with REVERSE replay (D→C→B→A)...\")\nX_rest_reverse = np.random.randn(n_rest_timepoints, n_sensors) * 0.3\n\n# Embed REVERSE sequence D→C→B→A at 40ms lag\nreverse_sequence = [3, 2, 1, 0]  # D→C→B→A\nreplay_times_reverse = []\n\nfor start_time in range(100, n_rest_timepoints - 100, 200):\n    replay_times_reverse.append(start_time)\n    for step, state in enumerate(reverse_sequence):\n        time_point = start_time + step * lag_samples\n        if time_point < n_rest_timepoints:\n            X_rest_reverse[time_point, state*10:(state+1)*10] += 1.5\n\nprint(f\"  Embedded {len(replay_times_reverse)} REVERSE replay events\")\nprint(f\"  Replay lag: 40ms between states\")\n\n# Decode reverse replay\nprint(\"\\nDecoding reverse replay...\")\nreactivation_probs_reverse = decoder.decode_states(X_rest_reverse)\n\n# Compute sequenceness for reverse replay\nprint(\"Computing sequenceness for reverse replay...\")\nsequenceness_reverse, _ = decoder.compute_sequenceness(\n    reactivation_probs_reverse, transition_matrix, alpha_control=True\n)\n\n# Find peak\npeak_idx_reverse = np.argmax(np.abs(sequenceness_reverse))\npeak_lag_reverse = time_lags[peak_idx_reverse]\npeak_value_reverse = sequenceness_reverse[peak_idx_reverse]\n\nprint(f\"\\nResults:\")\nprint(f\"  Peak sequenceness: {peak_value_reverse:.4f}\")\nprint(f\"  Peak lag: {peak_lag_reverse}ms\")\nprint(f\"  Direction: {'Forward' if peak_value_reverse > 0 else 'Backward (Reverse)'}\")"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## Part 3: Example 3 - Multiple Sequences\n",
    "\n",
    "Real experiments often have multiple possible sequences. Let's test with two interleaved sequences."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compare forward and reverse replay\n",
    "fig, axes = plt.subplots(1, 2, figsize=(14, 5))\n",
    "\n",
    "# Forward replay\n",
    "axes[0].plot(time_lags, sequenceness, 'b-', linewidth=2.5)\n",
    "axes[0].axhline(y=0, color='k', linestyle='--', alpha=0.3)\n",
    "axes[0].axhline(y=threshold, color='r', linestyle='--', linewidth=2)\n",
    "axes[0].axhline(y=-threshold, color='r', linestyle='--', linewidth=2)\n",
    "axes[0].axvline(x=40, color='green', linestyle=':', linewidth=2, alpha=0.7)\n",
    "axes[0].fill_between(time_lags, 0, sequenceness, where=(sequenceness > 0),\n",
    "                     alpha=0.3, color='blue')\n",
    "axes[0].set_xlabel('Time Lag (ms)', fontsize=12)\n",
    "axes[0].set_ylabel('Sequenceness', fontsize=12)\n",
    "axes[0].set_title('Forward Replay\\n(Before Reward: A→B→C→D)', fontsize=12, fontweight='bold')\n",
    "axes[0].grid(True, alpha=0.3)\n",
    "axes[0].text(0.05, 0.95, 'Forward\\n(positive)', transform=axes[0].transAxes,\n",
    "            fontsize=11, verticalalignment='top', bbox=dict(boxstyle='round', facecolor='lightblue', alpha=0.5))\n",
    "\n",
    "# Reverse replay\n",
    "axes[1].plot(time_lags, sequenceness_reverse, 'r-', linewidth=2.5)\n",
    "axes[1].axhline(y=0, color='k', linestyle='--', alpha=0.3)\n",
    "axes[1].axhline(y=threshold, color='r', linestyle='--', linewidth=2)\n",
    "axes[1].axhline(y=-threshold, color='r', linestyle='--', linewidth=2)\n",
    "axes[1].axvline(x=40, color='green', linestyle=':', linewidth=2, alpha=0.7)\n",
    "axes[1].fill_between(time_lags, 0, sequenceness_reverse, where=(sequenceness_reverse < 0),\n",
    "                     alpha=0.3, color='red')\n",
    "axes[1].set_xlabel('Time Lag (ms)', fontsize=12)\n",
    "axes[1].set_ylabel('Sequenceness', fontsize=12)\n",
    "axes[1].set_title('Reverse Replay\\n(After Reward: D→C→B→A)', fontsize=12, fontweight='bold')\n",
    "axes[1].grid(True, alpha=0.3)\n",
    "axes[1].text(0.05, 0.05, 'Backward\\n(negative)', transform=axes[1].transAxes,\n",
    "            fontsize=11, verticalalignment='bottom', bbox=dict(boxstyle='round', facecolor='lightcoral', alpha=0.5))\n",
    "\n",
    "plt.suptitle('Example 2: Direction Reversal After Reward', fontsize=14, fontweight='bold', y=1.02)\n",
    "plt.tight_layout()\n",
    "plt.savefig('sequenceness_example2_comparison.png', dpi=150, bbox_inches='tight')\n",
    "plt.show()\n",
    "\n",
    "print(\"\\nComparison complete!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# Use 8 states for two sequences\nn_states_multi = 8\ndecoder_multi = MultivariateReplayDecoder(n_states=n_states_multi, max_lag_ms=600)\n\n# Create training data for 8 states\nprint(\"Creating training data for 8 states (2 sequences)...\")\nX_train_multi = np.random.randn(400, n_timepoints_per_trial, n_sensors) * 0.5\ny_train_multi = np.random.randint(0, n_states_multi, 400)\n\n# Add signal for each state\nfor trial in range(400):\n    state = y_train_multi[trial]\n    X_train_multi[trial, time_idx, state*12:(state+1)*12] += 2.0\n\n# Train decoder\nprint(\"Training decoder for 8 states...\")\ndecoder_multi.train_classifiers(X_train_multi, y_train_multi, time_point_ms=200)\n\n# Define two sequences: Seq1 (0→1→2→3) and Seq2 (4→5→6→7)\ntransition_matrix_seq1 = np.zeros((8, 8))\ntransition_matrix_seq1[0, 1] = 1  # 0→1\ntransition_matrix_seq1[1, 2] = 1  # 1→2\ntransition_matrix_seq1[2, 3] = 1  # 2→3\n\ntransition_matrix_seq2 = np.zeros((8, 8))\ntransition_matrix_seq2[4, 5] = 1  # 4→5\ntransition_matrix_seq2[5, 6] = 1  # 5→6\ntransition_matrix_seq2[6, 7] = 1  # 6→7\n\nprint(\"\\nSequence 1: States 0→1→2→3\")\nprint(\"Sequence 2: States 4→5→6→7\")"
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": "# Simulate rest with ONLY Sequence 1 replay\nprint(\"\\nSimulating rest with Sequence 1 replay only...\")\nX_rest_multi = np.random.randn(n_rest_timepoints, n_sensors) * 0.3\n\n# Embed Sequence 1: 0→1→2→3\nseq1 = [0, 1, 2, 3]\nfor start_time in range(100, n_rest_timepoints - 100, 200):\n    for step, state in enumerate(seq1):\n        time_point = start_time + step * lag_samples\n        if time_point < n_rest_timepoints:\n            X_rest_multi[time_point, state*12:(state+1)*12] += 1.5\n\n# Decode\nprint(\"Decoding...\")\nreactivation_probs_multi = decoder_multi.decode_states(X_rest_multi)\n\n# Compute sequenceness for both sequences\nprint(\"\\nComputing sequenceness for both sequences...\")\nseq1_sequenceness, _ = decoder_multi.compute_sequenceness(\n    reactivation_probs_multi, transition_matrix_seq1\n)\nseq2_sequenceness, _ = decoder_multi.compute_sequenceness(\n    reactivation_probs_multi, transition_matrix_seq2\n)\n\n# Compare peaks\npeak1 = np.max(np.abs(seq1_sequenceness))\npeak2 = np.max(np.abs(seq2_sequenceness))\n\nprint(f\"\\nResults:\")\nprint(f\"  Sequence 1 peak: {peak1:.4f}\")\nprint(f\"  Sequence 2 peak: {peak2:.4f}\")\nprint(f\"  Ratio (Seq1/Seq2): {peak1/peak2:.2f}\")",
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "source": [
    "# Visualize both sequences\n",
    "fig, ax = plt.subplots(figsize=(12, 6))\n",
    "\n",
    "ax.plot(time_lags, seq1_sequenceness, 'b-', linewidth=2.5, label='Sequence 1 (0→1→2→3)', alpha=0.8)\n",
    "ax.plot(time_lags, seq2_sequenceness, 'orange', linewidth=2.5, label='Sequence 2 (4→5→6→7)', alpha=0.8)\n",
    "ax.axhline(y=0, color='k', linestyle='--', alpha=0.3)\n",
    "ax.axvline(x=40, color='green', linestyle=':', linewidth=2, alpha=0.7, label='True lag (40ms)')\n",
    "\n",
    "ax.set_xlabel('Time Lag (ms)', fontsize=12)\n",
    "ax.set_ylabel('Sequenceness', fontsize=12)\n",
    "ax.set_title('Example 3: Sequence-Specific Replay\\n(Only Sequence 1 was embedded in data)',\n",
    "            fontsize=14, fontweight='bold')\n",
    "ax.legend(loc='upper right', fontsize=11)\n",
    "ax.grid(True, alpha=0.3)\n",
    "\n",
    "# Add annotation\n",
    "ax.text(0.98, 0.95, f'Sequence 1 replays at 40ms\\nSequence 2 shows no replay',\n",
    "       transform=ax.transAxes, fontsize=11, verticalalignment='top', horizontalalignment='right',\n",
    "       bbox=dict(boxstyle='round', facecolor='wheat', alpha=0.5))\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig('sequenceness_example3_multi.png', dpi=150, bbox_inches='tight')\n",
    "plt.show()\n",
    "\n",
    "print(\"\\nMulti-sequence analysis complete!\")"
   ],
   "metadata": {},
   "execution_count": null,
   "outputs": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}